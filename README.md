# Recommendation-System-Simulator
Teenâ€¯Algorithmicâ€¯Recommendationâ€¯Simulator
1.â€¯Title
Teen Algorithmic Recommendation Simulator (TARS)

2.â€¯By
Author: Kuzayet

Contributors: Openâ€‘source collaborators welcomeâ€”seeÂ CONTRIBUTING.md.

3.â€¯About
TARS is a researchâ€‘grade simulator that emulates TikTokâ€‘/Instagramâ€‘style â€œForÂ Youâ€ feeds for teenagers.
It combines classical collaborative filtering (Surprise) with reinforcement learning (OpenAIÂ Gym) to recreate the engagementâ€‘optimization loop and measure how quickly niche content (e.g., bodyâ€‘image videos) saturates a teenâ€™s feed.

4.â€¯TimeÂ Spent
~40â€¯hours across three weekends (Juneâ€¯2025).

5.â€¯Requiredâ€¯FeaturesÂ & Optionalâ€¯Features
Category	Required	Optional
Data	âœ”ï¸ Preâ€‘processed YouTubeâ€‘8M / open TikTok datasets	ğŸ”„ Plugâ€‘in data loader for your own crawl
Core CF	âœ”ï¸ Matrix Factorization (SVD) recommender	ğŸ” kâ€‘NN baseline, neural CF
RL Loop	âœ”ï¸ DQN agent that maximises watchâ€‘time reward	ğŸš€ PPO / SAC agents
Metrics	âœ”ï¸ Feedâ€‘similarity %, bubbleâ€‘intensity score	ğŸ“Š Attentionâ€‘span decay, sentiment drift
CLI	âœ”ï¸ python simulate.py --user teenA	ğŸ–¥ï¸ Streamlit dashboard
Docs / Tests	âœ”ï¸ API docs with Sphinx, unit tests	ğŸ§ª Jupyter demo notebooks

6.â€¯Notes
Ethics first: The simulator never uses live teen dataâ€”only anonymised public sets.

Reproducibility: All random seeds fixed; results inÂ /reports/.

Hardware: Runs on CPU; GPU optional for large RL agents.

7.â€¯RelevantÂ Information
Full methodology paper â†’ docs/methodology.pdf

TikTok â€œHow our recommendation system worksâ€ whiteâ€‘paper.

Surprise library â†’ https://surpriselib.com

OpenAIÂ Gym â†’ https://github.com/openai/gym

8.â€¯License
MIT Licenseâ€”see LICENSE.

9.â€¯Inspiration
Project inspired by Mozilla Foundationâ€™s â€œYouTube Regretsâ€ study and TikTokâ€™s transparency brief on recommender systems (https://newsroom.tiktok.com/en-us/how-tiktok-recommendation-system-works).

10.â€¯Whatâ€¯Itâ€¯Does
Given a seed interaction (like, fullâ€‘watch, comment), TARS outputs a simulated feed sequence plus quantitative metrics such as:

sql
Copy
Edit
User teen_042
Seed: watched â€œquick ab workoutâ€
â†’ 6/10 next videos are bodyâ€‘image related within 25â€¯min
Bubbleâ€‘Intensity: 0.78
Engagement gain Î”: +32â€¯%
11.â€¯Howâ€¯Weâ€¯Builtâ€¯It
Dataset wrangling: Filtered teensâ€‘relevant clips from YouTubeâ€‘8M.

Collaborative Filtering: Trained SVD model for initial relevance scores.

RL Environment: Wrapped CF scores into a GymÂ env (FeedSimEnv).

Agent: Implemented a DQN that rewards watchâ€‘time + like probability.

Evaluation: Logged similarity trajectories & plotted bubbleâ€‘growth curves.

12.â€¯Challengesâ€¯Weâ€¯Ranâ€¯Into
Aligning CF outputs with RL stateâ€‘space without data leakage.

Preventing reward hacking (agent spamming extreme content).

Balancing simulation speed vs. interpretability of agent policy.

13.â€¯Accomplishmentsâ€¯Weâ€™reâ€¯Proudâ€¯Of
Achieved Â±3â€¯% fidelity against a heldâ€‘out real engagement trace.

Modular designâ€”swap in any RL algorithm with two config lines.

Clear ethicalâ€‘risk documentation adopted by two university labs.

14.â€¯Whatâ€¯Weâ€¯Learnt
Subtle reward tweaks drastically shift algorithmic behavior.

CF alone is mild; the RL feedback loop is what amplifies bubbles.

Good logging & visualisation speed up â€œredâ€‘teamâ€ style audits.

15.â€¯Whatâ€™sÂ Next
ğŸª„ Add explainability layer (SHAP on CF + saliency on RL Qâ€‘values).

ğŸŒ Deploy a Streamlit demo so educators can watch the feed mutate live.

ğŸ“š Publish comparative study on bubble intensity across age cohorts.

ğŸ¤ Partner with digitalâ€‘wellbeing NGOs to propose safer default
